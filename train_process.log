Start training

Train Epoch: 1 [0/24000 (0%)]	Loss: 0.023846
reconst_loss *lambda:  0.009519508481025696
squared_mahalanobis_distance_loss *lambda:  0.007940041273832322
Start training

Train Epoch: 1 [0/24000 (0%)]	Loss: 0.023846
reconst_loss *lambda:  0.009519508481025696
squared_mahalanobis_distance_loss *lambda:  0.007940041273832322
Start training

Train Epoch: 1 [0/24000 (0%)]	Loss: 0.029498
reconst_loss *lambda:  0.011857106350362301
squared_mahalanobis_distance_loss *lambda:  0.009785526432096958
Start training

Train Epoch: 1 [0/24000 (0%)]	Loss: 0.026345
reconst_loss *lambda:  0.010473303496837616
squared_mahalanobis_distance_loss *lambda:  0.00884246826171875
Start training

Train Epoch: 1 [0/24000 (0%)]	Loss: 0.026345
reconst_loss *lambda:  0.010473303496837616
squared_mahalanobis_distance_loss *lambda:  0.00884246826171875

Train Epoch: 1 [1800/24000 (8%)]	Loss: 0.009004
reconst_loss *lambda:  0.00415648768345515
squared_mahalanobis_distance_loss *lambda:  0.0004110632774730523

Train Epoch: 1 [3600/24000 (15%)]	Loss: 0.008793
reconst_loss *lambda:  0.004195535348521339
squared_mahalanobis_distance_loss *lambda:  0.00036618090234696865

Train Epoch: 1 [5400/24000 (23%)]	Loss: 0.007057
reconst_loss *lambda:  0.003349351386229197
squared_mahalanobis_distance_loss *lambda:  0.00017452454711827968

Train Epoch: 1 [7200/24000 (30%)]	Loss: 0.006717
reconst_loss *lambda:  0.0032077936662567984
squared_mahalanobis_distance_loss *lambda:  0.00012090061015139024

Train Epoch: 1 [9000/24000 (38%)]	Loss: 0.005094
reconst_loss *lambda:  0.0023799261285199057
squared_mahalanobis_distance_loss *lambda:  0.00011409634155117803

Train Epoch: 1 [10800/24000 (45%)]	Loss: 0.005825
reconst_loss *lambda:  0.0027591105964448717
squared_mahalanobis_distance_loss *lambda:  0.00012847807051406967

Train Epoch: 1 [12600/24000 (53%)]	Loss: 0.006092
reconst_loss *lambda:  0.0030043903324339124
squared_mahalanobis_distance_loss *lambda:  0.0002916850046151214

Train Epoch: 1 [14400/24000 (60%)]	Loss: 0.005645
reconst_loss *lambda:  0.0026918676578336293
squared_mahalanobis_distance_loss *lambda:  0.00012033794903092914

Train Epoch: 1 [16200/24000 (68%)]	Loss: 0.006410
reconst_loss *lambda:  0.0030858125537633896
squared_mahalanobis_distance_loss *lambda:  8.235743088233803e-05

Train Epoch: 1 [18000/24000 (75%)]	Loss: 0.004960
reconst_loss *lambda:  0.0022430202613274255
squared_mahalanobis_distance_loss *lambda:  8.793549689774711e-05

Train Epoch: 1 [19800/24000 (83%)]	Loss: 0.003684
reconst_loss *lambda:  0.0017150680844982464
squared_mahalanobis_distance_loss *lambda:  9.592377399611805e-05

Train Epoch: 1 [21600/24000 (90%)]	Loss: 0.003597
reconst_loss *lambda:  0.0015838249690002864
squared_mahalanobis_distance_loss *lambda:  8.128930090202225e-05

Train Epoch: 1 [23400/24000 (98%)]	Loss: 0.004184
reconst_loss *lambda:  0.0019023263206084569
squared_mahalanobis_distance_loss *lambda:  0.00012416044612311653
====> Epoch: 1 Average loss: 0.113132
====> Epoch: 1 Average reconst_loss *lambda: 0.051766
====> Epoch: 1 Average mono_loss *lambda: 0.057256
====> Epoch: 1 Average squared_mahalanobis_distance_loss *lambda: 0.004110
====> Epoch: 1 Average val loss: 0.071160
====> Epoch: 1 Average val reconst_loss *lambda: 0.030169
====> Epoch: 1 Average val mono_loss *lambda: 0.039829
====> Epoch: 1 Average val sparse_loss *lambda: 0.000000
====> Epoch: 1 Average val squared_mahalanobis_distance_loss *lambda: 0.001162
loss 0.6988 - dice 0.7191 - val_loss 0.6099 - val_dice 0.7799
=> saved best model
Start training

Train Epoch: 2 [0/24000 (0%)]	Loss: 0.003959
reconst_loss *lambda:  0.0017260365809003513
squared_mahalanobis_distance_loss *lambda:  0.00014844424246499935

Train Epoch: 2 [1800/24000 (8%)]	Loss: 0.004358
reconst_loss *lambda:  0.002048347352279557
squared_mahalanobis_distance_loss *lambda:  7.604043154666822e-05

Train Epoch: 2 [3600/24000 (15%)]	Loss: 0.004843
reconst_loss *lambda:  0.002270075182120005
squared_mahalanobis_distance_loss *lambda:  9.128385378668706e-05

Train Epoch: 2 [5400/24000 (23%)]	Loss: 0.003715
reconst_loss *lambda:  0.0016352232131693098
squared_mahalanobis_distance_loss *lambda:  0.0001057538902387023

Train Epoch: 2 [7200/24000 (30%)]	Loss: 0.003317
reconst_loss *lambda:  0.0013958118442032072
squared_mahalanobis_distance_loss *lambda:  7.750625566889842e-05

Train Epoch: 2 [9000/24000 (38%)]	Loss: 0.003303
reconst_loss *lambda:  0.001404212477306525
squared_mahalanobis_distance_loss *lambda:  6.372008808991975e-05

Train Epoch: 2 [10800/24000 (45%)]	Loss: 0.004015
reconst_loss *lambda:  0.0018576414634784062
squared_mahalanobis_distance_loss *lambda:  6.39024656265974e-05

Train Epoch: 2 [12600/24000 (53%)]	Loss: 0.003683
reconst_loss *lambda:  0.0016434753520621194
squared_mahalanobis_distance_loss *lambda:  8.22514023942252e-05

Train Epoch: 2 [14400/24000 (60%)]	Loss: 0.002242
reconst_loss *lambda:  0.000974769393603007
squared_mahalanobis_distance_loss *lambda:  4.6048248704108926e-05

Train Epoch: 2 [16200/24000 (68%)]	Loss: 0.003235
reconst_loss *lambda:  0.001387862799068292
squared_mahalanobis_distance_loss *lambda:  6.762402416724298e-05

Train Epoch: 2 [18000/24000 (75%)]	Loss: 0.003693
reconst_loss *lambda:  0.0016549890860915184
squared_mahalanobis_distance_loss *lambda:  6.451561219162411e-05

Train Epoch: 2 [19800/24000 (83%)]	Loss: 0.002188
reconst_loss *lambda:  0.0009294021874666214
squared_mahalanobis_distance_loss *lambda:  3.987316934702297e-05

Train Epoch: 2 [21600/24000 (90%)]	Loss: 0.002629
reconst_loss *lambda:  0.0010931056199802293
squared_mahalanobis_distance_loss *lambda:  6.309543581058581e-05

Train Epoch: 2 [23400/24000 (98%)]	Loss: 0.003721
reconst_loss *lambda:  0.0016165657175911798
squared_mahalanobis_distance_loss *lambda:  7.035248240249025e-05
====> Epoch: 2 Average loss: 0.066298
====> Epoch: 2 Average reconst_loss *lambda: 0.029648
====> Epoch: 2 Average mono_loss *lambda: 0.035370
====> Epoch: 2 Average squared_mahalanobis_distance_loss *lambda: 0.001280
====> Epoch: 2 Average val loss: 0.114675
====> Epoch: 2 Average val reconst_loss *lambda: 0.055536
====> Epoch: 2 Average val mono_loss *lambda: 0.058231
====> Epoch: 2 Average val sparse_loss *lambda: 0.000000
====> Epoch: 2 Average val squared_mahalanobis_distance_loss *lambda: 0.000908
loss 0.6077 - dice 0.7852 - val_loss 0.5999 - val_dice 0.7929
=> saved best model
Start training

Train Epoch: 3 [0/24000 (0%)]	Loss: 0.005243
reconst_loss *lambda:  0.0024863237308131326
squared_mahalanobis_distance_loss *lambda:  5.478585889149043e-05

Train Epoch: 3 [1800/24000 (8%)]	Loss: 0.002796
reconst_loss *lambda:  0.0011655764861239328
squared_mahalanobis_distance_loss *lambda:  5.217657114068667e-05

Train Epoch: 3 [3600/24000 (15%)]	Loss: 0.005317
reconst_loss *lambda:  0.0024775293552213246
squared_mahalanobis_distance_loss *lambda:  6.480552514808046e-05

Train Epoch: 3 [5400/24000 (23%)]	Loss: 0.002666
reconst_loss *lambda:  0.001143424150844415
squared_mahalanobis_distance_loss *lambda:  4.1101156966760755e-05

Train Epoch: 3 [7200/24000 (30%)]	Loss: 0.003593
reconst_loss *lambda:  0.001618335127002663
squared_mahalanobis_distance_loss *lambda:  5.068061161889798e-05

Train Epoch: 3 [9000/24000 (38%)]	Loss: 0.004721
reconst_loss *lambda:  0.0021387843622101676
squared_mahalanobis_distance_loss *lambda:  6.879490360410677e-05

Train Epoch: 3 [10800/24000 (45%)]	Loss: 0.002276
reconst_loss *lambda:  0.0009781930388675795
squared_mahalanobis_distance_loss *lambda:  3.828168135239846e-05

Train Epoch: 3 [12600/24000 (53%)]	Loss: 0.003227
reconst_loss *lambda:  0.0014008792738119762
squared_mahalanobis_distance_loss *lambda:  6.2805387036254e-05

Train Epoch: 3 [14400/24000 (60%)]	Loss: 0.002864
reconst_loss *lambda:  0.001167525744272603
squared_mahalanobis_distance_loss *lambda:  6.131851114332676e-05

Train Epoch: 3 [16200/24000 (68%)]	Loss: 0.004308
reconst_loss *lambda:  0.001988832942313618
squared_mahalanobis_distance_loss *lambda:  4.972881611643566e-05

Train Epoch: 3 [18000/24000 (75%)]	Loss: 0.003585
reconst_loss *lambda:  0.001559651249812709
squared_mahalanobis_distance_loss *lambda:  7.232208736240864e-05

Train Epoch: 3 [19800/24000 (83%)]	Loss: 0.002337
reconst_loss *lambda:  0.0009918200472990673
squared_mahalanobis_distance_loss *lambda:  4.3583293316057985e-05

Train Epoch: 3 [21600/24000 (90%)]	Loss: 0.003113
reconst_loss *lambda:  0.0014372713242967923
squared_mahalanobis_distance_loss *lambda:  3.878402963487638e-05

Train Epoch: 3 [23400/24000 (98%)]	Loss: 0.004696
reconst_loss *lambda:  0.0021877545449468824
squared_mahalanobis_distance_loss *lambda:  6.24888149710993e-05
====> Epoch: 3 Average loss: 0.058403
====> Epoch: 3 Average reconst_loss *lambda: 0.025730
====> Epoch: 3 Average mono_loss *lambda: 0.031737
====> Epoch: 3 Average squared_mahalanobis_distance_loss *lambda: 0.000935
====> Epoch: 3 Average val loss: 0.052029
====> Epoch: 3 Average val reconst_loss *lambda: 0.021358
====> Epoch: 3 Average val mono_loss *lambda: 0.029827
====> Epoch: 3 Average val sparse_loss *lambda: 0.000000
====> Epoch: 3 Average val squared_mahalanobis_distance_loss *lambda: 0.000843
loss 0.5826 - dice 0.8016 - val_loss 0.5664 - val_dice 0.8200
=> saved best model
Start training

Train Epoch: 4 [0/24000 (0%)]	Loss: 0.003274
reconst_loss *lambda:  0.0014414968382981089
squared_mahalanobis_distance_loss *lambda:  5.2345043513923883e-05

Train Epoch: 4 [1800/24000 (8%)]	Loss: 0.003723
reconst_loss *lambda:  0.0016820734987656276
squared_mahalanobis_distance_loss *lambda:  5.6669607551561465e-05

Train Epoch: 4 [3600/24000 (15%)]	Loss: 0.003313
reconst_loss *lambda:  0.0014757368092735608
squared_mahalanobis_distance_loss *lambda:  5.4473193207134805e-05

Train Epoch: 4 [5400/24000 (23%)]	Loss: 0.002287
reconst_loss *lambda:  0.0009705675765872002
squared_mahalanobis_distance_loss *lambda:  4.2334493223784695e-05

Train Epoch: 4 [7200/24000 (30%)]	Loss: 0.004007
reconst_loss *lambda:  0.0018070354643795225
squared_mahalanobis_distance_loss *lambda:  5.233638997500142e-05

Train Epoch: 4 [9000/24000 (38%)]	Loss: 0.004168
reconst_loss *lambda:  0.0019282054983907277
squared_mahalanobis_distance_loss *lambda:  5.6860457536660964e-05

Train Epoch: 4 [10800/24000 (45%)]	Loss: 0.003396
reconst_loss *lambda:  0.0015009856886333888
squared_mahalanobis_distance_loss *lambda:  4.420153305141462e-05

Train Epoch: 4 [12600/24000 (53%)]	Loss: 0.004379
reconst_loss *lambda:  0.0020058399273289573
squared_mahalanobis_distance_loss *lambda:  5.6019770757605634e-05

Train Epoch: 4 [14400/24000 (60%)]	Loss: 0.002181
reconst_loss *lambda:  0.0008941336224476496
squared_mahalanobis_distance_loss *lambda:  4.370556174156567e-05

Train Epoch: 4 [16200/24000 (68%)]	Loss: 0.002852
reconst_loss *lambda:  0.0012050487308038606
squared_mahalanobis_distance_loss *lambda:  5.2255018898803326e-05

Train Epoch: 4 [18000/24000 (75%)]	Loss: 0.002656
reconst_loss *lambda:  0.0011354837980535296
squared_mahalanobis_distance_loss *lambda:  4.921897198073566e-05

Train Epoch: 4 [19800/24000 (83%)]	Loss: 0.004811
reconst_loss *lambda:  0.0022809019105301965
squared_mahalanobis_distance_loss *lambda:  4.1130209057074455e-05

Train Epoch: 4 [21600/24000 (90%)]	Loss: 0.002306
reconst_loss *lambda:  0.0009543033730652598
squared_mahalanobis_distance_loss *lambda:  4.729451999689142e-05

Train Epoch: 4 [23400/24000 (98%)]	Loss: 0.002179
reconst_loss *lambda:  0.0009228220830361048
squared_mahalanobis_distance_loss *lambda:  4.628075273810989e-05
====> Epoch: 4 Average loss: 0.054274
====> Epoch: 4 Average reconst_loss *lambda: 0.023801
====> Epoch: 4 Average mono_loss *lambda: 0.029555
====> Epoch: 4 Average squared_mahalanobis_distance_loss *lambda: 0.000918
====> Epoch: 4 Average val loss: 0.042864
====> Epoch: 4 Average val reconst_loss *lambda: 0.017399
====> Epoch: 4 Average val mono_loss *lambda: 0.024729
====> Epoch: 4 Average val sparse_loss *lambda: 0.000000
====> Epoch: 4 Average val squared_mahalanobis_distance_loss *lambda: 0.000735
loss 0.5701 - dice 0.8090 - val_loss 0.5778 - val_dice 0.8163
Start training
