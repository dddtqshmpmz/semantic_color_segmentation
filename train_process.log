Start training

Train Epoch: 1 [0/24000 (0%)]	Loss: 0.024589
reconst_loss *lambda:  0.009913972020149231
squared_mahalanobis_distance_loss *lambda:  0.007888182252645492

Train Epoch: 1 [2000/24000 (8%)]	Loss: 0.010512
reconst_loss *lambda:  0.004712206125259399
squared_mahalanobis_distance_loss *lambda:  0.0005085050594061613

Train Epoch: 1 [4000/24000 (17%)]	Loss: 0.007794
reconst_loss *lambda:  0.0036338135600090028
squared_mahalanobis_distance_loss *lambda:  0.00022674989886581898

Train Epoch: 1 [6000/24000 (25%)]	Loss: 0.005852
reconst_loss *lambda:  0.0026867294684052466
squared_mahalanobis_distance_loss *lambda:  0.00017596370307728648

Train Epoch: 1 [8000/24000 (33%)]	Loss: 0.005055
reconst_loss *lambda:  0.002169785089790821
squared_mahalanobis_distance_loss *lambda:  0.00015772755723446607

Train Epoch: 1 [10000/24000 (42%)]	Loss: 0.004903
reconst_loss *lambda:  0.0022220242768526076
squared_mahalanobis_distance_loss *lambda:  0.00010402371408417821

Train Epoch: 1 [12000/24000 (50%)]	Loss: 0.004898
reconst_loss *lambda:  0.002318812347948551
squared_mahalanobis_distance_loss *lambda:  9.130713297054172e-05

Train Epoch: 1 [14000/24000 (58%)]	Loss: 0.003754
reconst_loss *lambda:  0.001663537509739399
squared_mahalanobis_distance_loss *lambda:  9.685357217676937e-05

Train Epoch: 1 [16000/24000 (67%)]	Loss: 0.004185
reconst_loss *lambda:  0.001864776387810707
squared_mahalanobis_distance_loss *lambda:  0.00010105508845299482

Train Epoch: 1 [18000/24000 (75%)]	Loss: 0.006052
reconst_loss *lambda:  0.0029371513053774835
squared_mahalanobis_distance_loss *lambda:  9.839067934080958e-05

Train Epoch: 1 [20000/24000 (83%)]	Loss: 0.004430
reconst_loss *lambda:  0.0020737128332257273
squared_mahalanobis_distance_loss *lambda:  7.532948511652648e-05

Train Epoch: 1 [22000/24000 (92%)]	Loss: 0.004676
reconst_loss *lambda:  0.0021409383043646812
squared_mahalanobis_distance_loss *lambda:  0.00010333211394026875
====> Epoch: 1 Average loss: 0.119740
====> Epoch: 1 Average reconst_loss *lambda: 0.054921
====> Epoch: 1 Average mono_loss *lambda: 0.060667
====> Epoch: 1 Average squared_mahalanobis_distance_loss *lambda: 0.004152
====> Epoch: 1 Average val loss: 0.063174
====> Epoch: 1 Average val reconst_loss *lambda: 0.026633
====> Epoch: 1 Average val mono_loss *lambda: 0.035382
====> Epoch: 1 Average val sparse_loss *lambda: 0.000000
====> Epoch: 1 Average val squared_mahalanobis_distance_loss *lambda: 0.001159
loss 0.6842 - dice 0.7301 - val_loss 0.7049 - val_dice 0.6989
=> saved best model
Start training

Train Epoch: 2 [0/24000 (0%)]	Loss: 0.004014
reconst_loss *lambda:  0.0019050195813179016
squared_mahalanobis_distance_loss *lambda:  8.534149965271354e-05

Train Epoch: 2 [2000/24000 (8%)]	Loss: 0.004719
reconst_loss *lambda:  0.0022546513006091117
squared_mahalanobis_distance_loss *lambda:  4.776539863087237e-05

Train Epoch: 2 [4000/24000 (17%)]	Loss: 0.003769
reconst_loss *lambda:  0.0017195001244544982
squared_mahalanobis_distance_loss *lambda:  7.712351507507264e-05

Train Epoch: 2 [6000/24000 (25%)]	Loss: 0.003718
reconst_loss *lambda:  0.0017121534794569016
squared_mahalanobis_distance_loss *lambda:  5.078283720649779e-05

Train Epoch: 2 [8000/24000 (33%)]	Loss: 0.003056
reconst_loss *lambda:  0.001307850144803524
squared_mahalanobis_distance_loss *lambda:  8.083541761152446e-05

Train Epoch: 2 [10000/24000 (42%)]	Loss: 0.003806
reconst_loss *lambda:  0.001684996485710144
squared_mahalanobis_distance_loss *lambda:  7.789524388499559e-05

Train Epoch: 2 [12000/24000 (50%)]	Loss: 0.004372
reconst_loss *lambda:  0.0020179588347673414
squared_mahalanobis_distance_loss *lambda:  7.168403244577349e-05

Train Epoch: 2 [14000/24000 (58%)]	Loss: 0.002809
reconst_loss *lambda:  0.0012958587147295475
squared_mahalanobis_distance_loss *lambda:  4.4969585724174975e-05

Train Epoch: 2 [16000/24000 (67%)]	Loss: 0.003565
reconst_loss *lambda:  0.0016362264752388
squared_mahalanobis_distance_loss *lambda:  4.947289708070457e-05

Train Epoch: 2 [18000/24000 (75%)]	Loss: 0.003072
reconst_loss *lambda:  0.0012530037201941013
squared_mahalanobis_distance_loss *lambda:  8.662025211378933e-05

Train Epoch: 2 [20000/24000 (83%)]	Loss: 0.002474
reconst_loss *lambda:  0.0010607062838971614
squared_mahalanobis_distance_loss *lambda:  5.875391070730984e-05

Train Epoch: 2 [22000/24000 (92%)]	Loss: 0.002692
reconst_loss *lambda:  0.0010984916239976882
squared_mahalanobis_distance_loss *lambda:  7.231219206005335e-05
====> Epoch: 2 Average loss: 0.068427
====> Epoch: 2 Average reconst_loss *lambda: 0.030628
====> Epoch: 2 Average mono_loss *lambda: 0.036524
====> Epoch: 2 Average squared_mahalanobis_distance_loss *lambda: 0.001275
====> Epoch: 2 Average val loss: 0.055381
====> Epoch: 2 Average val reconst_loss *lambda: 0.023159
====> Epoch: 2 Average val mono_loss *lambda: 0.031062
====> Epoch: 2 Average val sparse_loss *lambda: 0.000000
====> Epoch: 2 Average val squared_mahalanobis_distance_loss *lambda: 0.001159
loss 0.6064 - dice 0.7859 - val_loss 0.5832 - val_dice 0.8170
=> saved best model
Start training

Train Epoch: 3 [0/24000 (0%)]	Loss: 0.003126
reconst_loss *lambda:  0.0013934656977653503
squared_mahalanobis_distance_loss *lambda:  5.2508991211652754e-05

Train Epoch: 3 [2000/24000 (8%)]	Loss: 0.002191
reconst_loss *lambda:  0.0009104288183152676
squared_mahalanobis_distance_loss *lambda:  5.027945153415203e-05

Train Epoch: 3 [4000/24000 (17%)]	Loss: 0.003798
reconst_loss *lambda:  0.0016529938206076623
squared_mahalanobis_distance_loss *lambda:  7.3839642573148e-05

Train Epoch: 3 [6000/24000 (25%)]	Loss: 0.003760
reconst_loss *lambda:  0.0017343686893582344
squared_mahalanobis_distance_loss *lambda:  4.684544692281634e-05

Train Epoch: 3 [8000/24000 (33%)]	Loss: 0.002703
reconst_loss *lambda:  0.0011697747744619847
squared_mahalanobis_distance_loss *lambda:  4.135546914767474e-05

Train Epoch: 3 [10000/24000 (42%)]	Loss: 0.003807
reconst_loss *lambda:  0.0017428897321224214
squared_mahalanobis_distance_loss *lambda:  5.0997798098251224e-05

Train Epoch: 3 [12000/24000 (50%)]	Loss: 0.003736
reconst_loss *lambda:  0.0017149802297353745
squared_mahalanobis_distance_loss *lambda:  5.267491796985268e-05

Train Epoch: 3 [14000/24000 (58%)]	Loss: 0.003155
reconst_loss *lambda:  0.0013921505771577359
squared_mahalanobis_distance_loss *lambda:  4.839995235670358e-05

Train Epoch: 3 [16000/24000 (67%)]	Loss: 0.003559
reconst_loss *lambda:  0.0016521507874131202
squared_mahalanobis_distance_loss *lambda:  4.467262770049274e-05

Train Epoch: 3 [18000/24000 (75%)]	Loss: 0.002259
reconst_loss *lambda:  0.0009479034692049026
squared_mahalanobis_distance_loss *lambda:  4.8257145681418476e-05

Train Epoch: 3 [20000/24000 (83%)]	Loss: 0.004351
reconst_loss *lambda:  0.0019701410084962843
squared_mahalanobis_distance_loss *lambda:  6.314005586318671e-05

Train Epoch: 3 [22000/24000 (92%)]	Loss: 0.002321
reconst_loss *lambda:  0.0009111925959587097
squared_mahalanobis_distance_loss *lambda:  5.252975388430059e-05
====> Epoch: 3 Average loss: 0.058354
====> Epoch: 3 Average reconst_loss *lambda: 0.025317
====> Epoch: 3 Average mono_loss *lambda: 0.031965
====> Epoch: 3 Average squared_mahalanobis_distance_loss *lambda: 0.001071
====> Epoch: 3 Average val loss: 0.077163
====> Epoch: 3 Average val reconst_loss *lambda: 0.036103
====> Epoch: 3 Average val mono_loss *lambda: 0.040272
====> Epoch: 3 Average val sparse_loss *lambda: 0.000000
====> Epoch: 3 Average val squared_mahalanobis_distance_loss *lambda: 0.000789
loss 0.5797 - dice 0.8047 - val_loss 0.5824 - val_dice 0.8062
Start training

Train Epoch: 4 [0/24000 (0%)]	Loss: 0.004105
reconst_loss *lambda:  0.0019038548693060876
squared_mahalanobis_distance_loss *lambda:  4.547440330497921e-05

Train Epoch: 4 [2000/24000 (8%)]	Loss: 0.002976
reconst_loss *lambda:  0.001271010749042034
squared_mahalanobis_distance_loss *lambda:  5.593191599473357e-05

Train Epoch: 4 [4000/24000 (17%)]	Loss: 0.002397
reconst_loss *lambda:  0.0010400556027889251
squared_mahalanobis_distance_loss *lambda:  3.7123836227692665e-05

Train Epoch: 4 [6000/24000 (25%)]	Loss: 0.002675
reconst_loss *lambda:  0.001121637225151062
squared_mahalanobis_distance_loss *lambda:  5.3048133850097656e-05

Train Epoch: 4 [8000/24000 (33%)]	Loss: 0.003851
reconst_loss *lambda:  0.0017061559483408928
squared_mahalanobis_distance_loss *lambda:  7.196929655037821e-05

Train Epoch: 4 [10000/24000 (42%)]	Loss: 0.002332
reconst_loss *lambda:  0.000959818996489048
squared_mahalanobis_distance_loss *lambda:  4.9975491128861905e-05

Train Epoch: 4 [12000/24000 (50%)]	Loss: 0.003196
reconst_loss *lambda:  0.0013849888928234577
squared_mahalanobis_distance_loss *lambda:  6.279880180954933e-05

Train Epoch: 4 [14000/24000 (58%)]	Loss: 0.002516
reconst_loss *lambda:  0.001054674107581377
squared_mahalanobis_distance_loss *lambda:  5.948324105702341e-05

Train Epoch: 4 [16000/24000 (67%)]	Loss: 0.002693
reconst_loss *lambda:  0.0011550402268767357
squared_mahalanobis_distance_loss *lambda:  4.89256635773927e-05
====> Epoch: 4 Average loss: 0.053663
====> Epoch: 4 Average reconst_loss *lambda: 0.023171
====> Epoch: 4 Average mono_loss *lambda: 0.029504
====> Epoch: 4 Average squared_mahalanobis_distance_loss *lambda: 0.000987
loss 0.5668 - dice 0.8141 - val_loss 0.5912 - val_dice 0.8170
=> saved best model
Start training
loss 0.5328 - dice 0.8360 - val_loss 0.5571 - val_dice 0.8292
=> saved best model
Start training
loss 0.5311 - dice 0.8360 - val_loss 0.5221 - val_dice 0.8470
=> saved best model
Start training
loss 0.5257 - dice 0.8392 - val_loss 0.5332 - val_dice 0.8382
Start training
loss 0.5224 - dice 0.8408 - val_loss 0.5166 - val_dice 0.8507
=> saved best model
Start training
loss 0.5183 - dice 0.8431 - val_loss 0.5334 - val_dice 0.8378
Start training
