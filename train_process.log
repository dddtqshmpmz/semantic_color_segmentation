Start training

Train Epoch: 1 [0/24000 (0%)]	Loss: 0.026167
reconst_loss *lambda:  0.010787526518106461
squared_mahalanobis_distance_loss *lambda:  0.00795995220541954

Train Epoch: 1 [2000/24000 (8%)]	Loss: 0.008750
reconst_loss *lambda:  0.0039850201457738875
squared_mahalanobis_distance_loss *lambda:  0.0004093498457223177

Train Epoch: 1 [4000/24000 (17%)]	Loss: 0.008700
reconst_loss *lambda:  0.004076514765620232
squared_mahalanobis_distance_loss *lambda:  0.0005474586971104145

Train Epoch: 1 [6000/24000 (25%)]	Loss: 0.006598
reconst_loss *lambda:  0.0031661998480558397
squared_mahalanobis_distance_loss *lambda:  0.0001208037487231195

Train Epoch: 1 [8000/24000 (33%)]	Loss: 0.007658
reconst_loss *lambda:  0.0036568939685821533
squared_mahalanobis_distance_loss *lambda:  0.00014825084945186974

Train Epoch: 1 [10000/24000 (42%)]	Loss: 0.006592
reconst_loss *lambda:  0.0032017592340707777
squared_mahalanobis_distance_loss *lambda:  9.875872638076544e-05

Train Epoch: 1 [12000/24000 (50%)]	Loss: 0.005793
reconst_loss *lambda:  0.0026741597801446916
squared_mahalanobis_distance_loss *lambda:  0.00011139254784211516

Train Epoch: 1 [14000/24000 (58%)]	Loss: 0.004061
reconst_loss *lambda:  0.0018122000619769096
squared_mahalanobis_distance_loss *lambda:  0.00011783739319071174

Train Epoch: 1 [16000/24000 (67%)]	Loss: 0.006172
reconst_loss *lambda:  0.0029536504298448563
squared_mahalanobis_distance_loss *lambda:  7.651748019270599e-05

Train Epoch: 1 [18000/24000 (75%)]	Loss: 0.005820
reconst_loss *lambda:  0.0027703335508704185
squared_mahalanobis_distance_loss *lambda:  0.00015791082987561821

Train Epoch: 1 [20000/24000 (83%)]	Loss: 0.004684
reconst_loss *lambda:  0.002271025255322456
squared_mahalanobis_distance_loss *lambda:  6.773865316063165e-05

Train Epoch: 1 [22000/24000 (92%)]	Loss: 0.003718
reconst_loss *lambda:  0.0017124630510807037
squared_mahalanobis_distance_loss *lambda:  7.265111780725419e-05
====> Epoch: 1 Average loss: 0.124788
====> Epoch: 1 Average reconst_loss *lambda: 0.057599
====> Epoch: 1 Average mono_loss *lambda: 0.062664
====> Epoch: 1 Average squared_mahalanobis_distance_loss *lambda: 0.004524
====> Epoch: 1 Average val loss: 0.088777
====> Epoch: 1 Average val reconst_loss *lambda: 0.040856
====> Epoch: 1 Average val mono_loss *lambda: 0.044974
====> Epoch: 1 Average val sparse_loss *lambda: 0.000000
====> Epoch: 1 Average val squared_mahalanobis_distance_loss *lambda: 0.002946
loss 0.6729 - dice 0.7400 - val_loss 0.7003 - val_dice 0.7255
=> saved best model
Start training

Train Epoch: 2 [0/24000 (0%)]	Loss: 0.004394
reconst_loss *lambda:  0.002060675621032715
squared_mahalanobis_distance_loss *lambda:  9.361173724755644e-05

Train Epoch: 2 [2000/24000 (8%)]	Loss: 0.002916
reconst_loss *lambda:  0.0014057169668376447
squared_mahalanobis_distance_loss *lambda:  0.00010960293002426624

Train Epoch: 2 [4000/24000 (17%)]	Loss: 0.004260
reconst_loss *lambda:  0.0019593071192502975
squared_mahalanobis_distance_loss *lambda:  7.436031592078507e-05

Train Epoch: 2 [6000/24000 (25%)]	Loss: 0.004496
reconst_loss *lambda:  0.0020920857787132263
squared_mahalanobis_distance_loss *lambda:  6.63811806589365e-05

Train Epoch: 2 [8000/24000 (33%)]	Loss: 0.004051
reconst_loss *lambda:  0.001845967583358288
squared_mahalanobis_distance_loss *lambda:  8.993344381451607e-05

Train Epoch: 2 [10000/24000 (42%)]	Loss: 0.004734
reconst_loss *lambda:  0.002201694995164871
squared_mahalanobis_distance_loss *lambda:  8.950646151788533e-05

Train Epoch: 2 [12000/24000 (50%)]	Loss: 0.002936
reconst_loss *lambda:  0.0012819014489650726
squared_mahalanobis_distance_loss *lambda:  6.220052018761635e-05

Train Epoch: 2 [14000/24000 (58%)]	Loss: 0.003272
reconst_loss *lambda:  0.0014636413194239139
squared_mahalanobis_distance_loss *lambda:  7.981358212418854e-05

Train Epoch: 2 [16000/24000 (67%)]	Loss: 0.005708
reconst_loss *lambda:  0.0027510492131114007
squared_mahalanobis_distance_loss *lambda:  6.987086962908506e-05

Train Epoch: 2 [18000/24000 (75%)]	Loss: 0.002904
reconst_loss *lambda:  0.0012645457871258258
squared_mahalanobis_distance_loss *lambda:  5.942168645560742e-05

Train Epoch: 2 [20000/24000 (83%)]	Loss: 0.003516
reconst_loss *lambda:  0.0016216391697525979
squared_mahalanobis_distance_loss *lambda:  4.8018438974395394e-05

Train Epoch: 2 [22000/24000 (92%)]	Loss: 0.003493
reconst_loss *lambda:  0.0015817468985915184
squared_mahalanobis_distance_loss *lambda:  6.165719241835177e-05
====> Epoch: 2 Average loss: 0.072092
====> Epoch: 2 Average reconst_loss *lambda: 0.032510
====> Epoch: 2 Average mono_loss *lambda: 0.038066
====> Epoch: 2 Average squared_mahalanobis_distance_loss *lambda: 0.001516
====> Epoch: 2 Average val loss: 0.045049
====> Epoch: 2 Average val reconst_loss *lambda: 0.017471
====> Epoch: 2 Average val mono_loss *lambda: 0.026530
====> Epoch: 2 Average val sparse_loss *lambda: 0.000000
====> Epoch: 2 Average val squared_mahalanobis_distance_loss *lambda: 0.001049
loss 0.5972 - dice 0.7929 - val_loss 0.5885 - val_dice 0.8122
=> saved best model
Start training

Train Epoch: 3 [0/24000 (0%)]	Loss: 0.002645
reconst_loss *lambda:  0.0011331026442348957
squared_mahalanobis_distance_loss *lambda:  6.468442734330893e-05

Train Epoch: 3 [2000/24000 (8%)]	Loss: 0.002789
reconst_loss *lambda:  0.001243752520531416
squared_mahalanobis_distance_loss *lambda:  5.541898426599801e-05

Train Epoch: 3 [4000/24000 (17%)]	Loss: 0.005164
reconst_loss *lambda:  0.002439395897090435
squared_mahalanobis_distance_loss *lambda:  7.484132656827569e-05

Train Epoch: 3 [6000/24000 (25%)]	Loss: 0.003416
reconst_loss *lambda:  0.0015076102688908577
squared_mahalanobis_distance_loss *lambda:  7.512258598580956e-05

Train Epoch: 3 [8000/24000 (33%)]	Loss: 0.003877
reconst_loss *lambda:  0.0018239371478557588
squared_mahalanobis_distance_loss *lambda:  5.720555200241506e-05

Train Epoch: 3 [10000/24000 (42%)]	Loss: 0.002604
reconst_loss *lambda:  0.0011494030244648457
squared_mahalanobis_distance_loss *lambda:  7.290708599612117e-05

Train Epoch: 3 [12000/24000 (50%)]	Loss: 0.002999
reconst_loss *lambda:  0.0013179030269384385
squared_mahalanobis_distance_loss *lambda:  6.736367358826101e-05

Train Epoch: 3 [14000/24000 (58%)]	Loss: 0.002512
reconst_loss *lambda:  0.0010493754409253598
squared_mahalanobis_distance_loss *lambda:  6.368081667460502e-05

Train Epoch: 3 [16000/24000 (67%)]	Loss: 0.002906
reconst_loss *lambda:  0.0012941963039338588
squared_mahalanobis_distance_loss *lambda:  6.122156628407538e-05

Train Epoch: 3 [18000/24000 (75%)]	Loss: 0.003889
reconst_loss *lambda:  0.001817108877003193
squared_mahalanobis_distance_loss *lambda:  4.171339969616383e-05

Train Epoch: 3 [20000/24000 (83%)]	Loss: 0.002133
reconst_loss *lambda:  0.0008604926057159901
squared_mahalanobis_distance_loss *lambda:  4.694382078014314e-05

Train Epoch: 3 [22000/24000 (92%)]	Loss: 0.002766
reconst_loss *lambda:  0.0011599558405578137
squared_mahalanobis_distance_loss *lambda:  5.364367971196771e-05
====> Epoch: 3 Average loss: 0.061168
====> Epoch: 3 Average reconst_loss *lambda: 0.027173
====> Epoch: 3 Average mono_loss *lambda: 0.032755
====> Epoch: 3 Average squared_mahalanobis_distance_loss *lambda: 0.001240
====> Epoch: 3 Average val loss: 0.097844
====> Epoch: 3 Average val reconst_loss *lambda: 0.046444
====> Epoch: 3 Average val mono_loss *lambda: 0.050643
====> Epoch: 3 Average val sparse_loss *lambda: 0.000000
====> Epoch: 3 Average val squared_mahalanobis_distance_loss *lambda: 0.000756
loss 0.5739 - dice 0.8085 - val_loss 0.5847 - val_dice 0.8171
=> saved best model
Start training

Train Epoch: 4 [0/24000 (0%)]	Loss: 0.004471
reconst_loss *lambda:  0.0020825089886784554
squared_mahalanobis_distance_loss *lambda:  5.193300312384963e-05

Train Epoch: 4 [2000/24000 (8%)]	Loss: 0.002838
reconst_loss *lambda:  0.0012084498070180417
squared_mahalanobis_distance_loss *lambda:  6.627531838603318e-05

Train Epoch: 4 [4000/24000 (17%)]	Loss: 0.003720
reconst_loss *lambda:  0.0016437135636806488
squared_mahalanobis_distance_loss *lambda:  5.761525244452059e-05

Train Epoch: 4 [6000/24000 (25%)]	Loss: 0.002593
reconst_loss *lambda:  0.0011059855110943317
squared_mahalanobis_distance_loss *lambda:  4.53440094133839e-05

Train Epoch: 4 [8000/24000 (33%)]	Loss: 0.003553
reconst_loss *lambda:  0.0016440015286207199
squared_mahalanobis_distance_loss *lambda:  5.4581003496423364e-05

Train Epoch: 4 [10000/24000 (42%)]	Loss: 0.002182
reconst_loss *lambda:  0.0009009762667119503
squared_mahalanobis_distance_loss *lambda:  4.587943258229643e-05

Train Epoch: 4 [12000/24000 (50%)]	Loss: 0.002257
reconst_loss *lambda:  0.0009557588025927543
squared_mahalanobis_distance_loss *lambda:  4.923687083646655e-05
====> Epoch: 4 Average loss: 0.057280
====> Epoch: 4 Average reconst_loss *lambda: 0.025213
====> Epoch: 4 Average mono_loss *lambda: 0.031083
====> Epoch: 4 Average squared_mahalanobis_distance_loss *lambda: 0.000983
loss 0.5606 - dice 0.8156 - val_loss 0.5503 - val_dice 0.8337
=> saved best model
Start training
loss 0.5307 - dice 0.8368 - val_loss 0.5424 - val_dice 0.8320
Start training
loss 0.5256 - dice 0.8402 - val_loss 0.5289 - val_dice 0.8453
=> saved best model
Start training
loss 0.5241 - dice 0.8404 - val_loss 0.5213 - val_dice 0.8476
=> saved best model
Start training
loss 0.5190 - dice 0.8433 - val_loss 0.5569 - val_dice 0.8312
Start training
loss 0.5155 - dice 0.8456 - val_loss 0.5197 - val_dice 0.8500
=> saved best model
Start training
loss 0.5097 - dice 0.8487 - val_loss 0.5124 - val_dice 0.8501
=> saved model every 10 epochs
=> saved best model
Start training
loss 0.5063 - dice 0.8501 - val_loss 0.5068 - val_dice 0.8583
=> saved best model
Start training
loss 0.5048 - dice 0.8509 - val_loss 0.5111 - val_dice 0.8499
Start training
loss 0.4995 - dice 0.8535 - val_loss 0.5505 - val_dice 0.8251
Start training
loss 0.4980 - dice 0.8542 - val_loss 0.5170 - val_dice 0.8487
Start training
loss 0.4949 - dice 0.8561 - val_loss 0.5000 - val_dice 0.8535
Start training
loss 0.4930 - dice 0.8579 - val_loss 0.4940 - val_dice 0.8588
=> saved best model
Start training
loss 0.4904 - dice 0.8586 - val_loss 0.5256 - val_dice 0.8452
Start training
loss 0.4876 - dice 0.8603 - val_loss 0.5111 - val_dice 0.8529
Start training
loss 0.4857 - dice 0.8611 - val_loss 0.4912 - val_dice 0.8615
=> saved best model
Start training
loss 0.4824 - dice 0.8629 - val_loss 0.4859 - val_dice 0.8643
=> saved model every 10 epochs
=> saved best model
Start training
